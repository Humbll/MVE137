{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42d4e64",
   "metadata": {},
   "source": [
    "**Project Assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325c54a",
   "metadata": {},
   "source": [
    "**Formalities**\n",
    "\n",
    "This is the project for the course Probability and Statistical Learning Using Python, 2023. Here, you are asked to carry out the analysis using the tools, techniques, and skills acquired in the course and hand in a .pynb file with the solutions.\n",
    "\n",
    "The **deadline  is Friday, October\n",
    "27, 2023.** You should upload the solution file to 'Project Assignment' in Canvas via 'Home-->Project Assignment'.\n",
    "Note that this is an individual exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab58442",
   "metadata": {},
   "source": [
    "**Part I**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a735f",
   "metadata": {},
   "source": [
    "In this exercise we will estimate the test error of logistic regression model using the below described validation set approach. You will neeed to import the *Default.csv* file provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679f0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "import patsy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b68f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "#Uncomment and set the path to the csv file below\n",
    "#df = pd.read_csv(\"Path\\Default.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6928055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e4c6d",
   "metadata": {},
   "source": [
    "(a) Fit a logistic regression model that uses $income$ and $balance$ to\n",
    "predict $default$ and print out the summary. **(3 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786cea44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5302291b",
   "metadata": {},
   "source": [
    "(b) You are supposed to estimate the test error of this model using the validation set approach described below. In order to do this, you must perform the following steps: **(4 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31129a5",
   "metadata": {},
   "source": [
    "i. Split the sample set into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff91e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df41deb6",
   "metadata": {},
   "source": [
    "ii. Fit a multiple logistic regression model using only the training\n",
    "observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52306566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83e13126",
   "metadata": {},
   "source": [
    "iii. Obtain a prediction of default status for each individual in\n",
    "the validation set (test set) by computing the posterior probability of\n",
    "$default$ for that individual, and classifying the individual to\n",
    "the $default$ category if the posterior probability is greater\n",
    "than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4618f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b8bfa3b",
   "metadata": {},
   "source": [
    "iv. Compute the validation set error, which is the fraction of\n",
    "the observations in the validation set (test set) that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a636670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88f375ea",
   "metadata": {},
   "source": [
    "(c) Now consider a logistic regression model that predicts the probability of default using $income$, $balance$, a dummy variable for $student$ and print the summary. Estimate the test error for this model using the validation\n",
    "set approach. Comment on the results. Does the inclusion of a dummy variable for student lead to a reduction in the test error? **(3 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e54900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a0f6b09",
   "metadata": {},
   "source": [
    "**Part II**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb2b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f0854",
   "metadata": {},
   "source": [
    "In this exercise, you will demonstrate your understanding of the KNN classification algorithm and test it on a breast cancer dataset. The algorithm should be implemented in pure python, without using the sklearn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ce805",
   "metadata": {},
   "source": [
    "**KNN algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048b3fc",
   "metadata": {},
   "source": [
    "(a)  Implement a function of your own to perform KNN classification **without using the default available libraries such as KNeighborsClassifier() in sklearn**. You will need to consider the Euclidean distances between the features and data to be predicted (test data) when selecting the k-nearest neighbors. The function should take 3 inputs as 1) data set to train the model 2) data to test 3) number of neighbours (k). If *k* is set to a value less than or equal to the total classification groups, the function should give a warning, and  warn() function defined in the 'warning' module will be useful for that.\n",
    "\n",
    "The function should output *classification_result*, where *classification_result* is the result of your classifier. Further, you should provide a suitable measure of the confidence on the classification. Justify your choice. \n",
    "\n",
    "Please note that only a few basic libraries/modules are imported and thus you are expected to import the needed others. \n",
    "\n",
    "\n",
    "\n",
    "**Hint:** You may fill and complete the function given below.                **(5 pts)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d468242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_algorithm(traindata, testdata, k_neighbours=5):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return classification_result, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b1202",
   "metadata": {},
   "source": [
    "#### Now let's test the implemented KNN algorithm on the given breast cancer dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd0f63",
   "metadata": {},
   "source": [
    "This dataset contains records of breast cancer patients. Here we will use the features (columns) to predict the correct cancer class (last column) for the patients in the dataset as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27af2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id', 'clump_thickness', 'unif_cell_size', 'unif_cell_shape', 'marg_adhesion',\n",
    "           'single_epith_cell_size', 'bare_nuclei', 'bland_chrom', 'norm_nucleoli', 'mitoses', 'class']\n",
    "#Import the data file by uncommenting below and setting the path to the dataset\n",
    "#df = pd.read_csv('Path/breast-cancer-wisconsin.data', header=None, names=columns)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb999d6b",
   "metadata": {},
   "source": [
    "#### Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be7ad9",
   "metadata": {},
   "source": [
    "(b) Check how many different cancer classes are available, and plot a pie chart to see the distribution of classes. Then, find and replace all the missing values with the mode of the particular column(s). Note that the missing values are marked with '?' in the dataset. **(1 pt)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4883d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d80206cd",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a7b6c",
   "metadata": {},
   "source": [
    "(c) Drop the obiviously unwanted column(s). **(1 pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67debe30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9f60fc",
   "metadata": {},
   "source": [
    "#### Split the training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7067dc",
   "metadata": {},
   "source": [
    "(d) In here, you will split the data into training and test sets, **without using sklearn library.** Please use 20% of the dataset as test set and the rest for train set. Shuffle the data prior to splitting in order to prevent any bias during the training and to avoid the model from learning the order of the training. **(5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e09a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04eda4a2",
   "metadata": {},
   "source": [
    "#### Predict the class for test data and calculate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173dff6",
   "metadata": {},
   "source": [
    "(e) Now train the KNN classifier you developed in (a) using the training set, and test it on the test set with *k_neighbours=5*. **(4 pts)**\n",
    "\n",
    "Print the confidence for the incorrect predictions the classifier has made.\n",
    "\n",
    "Find the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad73b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f358925",
   "metadata": {},
   "source": [
    "The accuracy is lower than the previous case. This is because the test set is larger, so the model is less likely to be able to predict the correct class.\n",
    "The confidence for incorrect predictions is higher than the previous case. This is because the test set is larger, so the model is less like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5137829",
   "metadata": {},
   "source": [
    "(f) Now increase the test set size to 40% of the dataset while keeping the same *k_neighbours* and print the confidence and accuracy of the predictions similar to the previous question. Explain the results in comparison with (e) **(2 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f89bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33a84cc8",
   "metadata": {},
   "source": [
    "#### Alternative classification methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c8ec6",
   "metadata": {},
   "source": [
    "(g) Propose alternative classification approaches for this problem and discuss the advantages and disadvantages with respect to KNNs (you don't need to implement them). **(2 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168fae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
